{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOvskKAthNiDVjUPiv1E+bP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khadidja2005/Pytorch_practice/blob/main/digits_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "2C3lg6X9vTQ5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculating mean and std for transform\n",
        "\n",
        "datasett = datasets.MNIST(root = \"/data\" , train = True , download = True ,transform = transforms.ToTensor())\n",
        "loader = DataLoader(datasett, batch_size=60000, shuffle=False)\n",
        "data = next(iter(loader))[0]\n",
        "mean = data.mean().item()\n",
        "std = data.std().item()\n",
        "print(f\"mean : {mean} , std : {std}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUYzuha-zhsb",
        "outputId": "07dcd144-551e-4a59-facc-686f3d8bc10e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean : 0.13066047430038452 , std : 0.30810782313346863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean = mean , std= std)\n",
        "])\n",
        "train_dataset = datasets.MNIST(root = \"/data\" , train = True , download = True , transform = transform)\n",
        "test_dataset = datasets.MNIST(root = \"/data\" , train = False , download = True , transform = transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset , batch_size=64 , shuffle=True)\n",
        "test_loader = DataLoader(test_dataset , batch_size= 1000 , shuffle=False)\n"
      ],
      "metadata": {
        "id": "dzz2OA7C3OI7"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available and being used.\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"No GPU available, using the CPU instead.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ak_yTDPOBk5S",
        "outputId": "cb383adf-3fa9-45f9-a51b-ca8b782d0e78"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available and being used.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNNModel , self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1 , 32 , kernel_size=3)\n",
        "    self.conv2 = nn.Conv2d(32 , 64 , kernel_size=3)\n",
        "    self.fc1 = nn.Linear(64*12*12 , 128)\n",
        "    self.fc2 = nn.Linear(128 , 10)\n",
        "  def forward(self , x):\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = F.max_pool2d(x , 2)\n",
        "    x = torch.flatten(x , 1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return F.log_softmax(x , dim = 1)\n",
        "model = CNNModel().to(device)"
      ],
      "metadata": {
        "id": "gjzjj61C6o_9"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters() , lr=0.001)\n"
      ],
      "metadata": {
        "id": "1yHKt5hv9zHt"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "  model.train()\n",
        "  for indx , (data , target) in enumerate(train_loader):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(data)\n",
        "    loss = criterion(outputs , target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if indx % 100 == 0:\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Batch {indx}/{len(train_loader)}, Loss: {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg_1KLIs_ty-",
        "outputId": "407dc027-f204-4101-e970-550ea33f8523"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Batch 0/938, Loss: 2.3004374504089355\n",
            "Epoch 1/10, Batch 100/938, Loss: 0.075043223798275\n",
            "Epoch 1/10, Batch 200/938, Loss: 0.08667907118797302\n",
            "Epoch 1/10, Batch 300/938, Loss: 0.0908079445362091\n",
            "Epoch 1/10, Batch 400/938, Loss: 0.10597997903823853\n",
            "Epoch 1/10, Batch 500/938, Loss: 0.03666553646326065\n",
            "Epoch 1/10, Batch 600/938, Loss: 0.16997814178466797\n",
            "Epoch 1/10, Batch 700/938, Loss: 0.046140190213918686\n",
            "Epoch 1/10, Batch 800/938, Loss: 0.052586689591407776\n",
            "Epoch 1/10, Batch 900/938, Loss: 0.03759946674108505\n",
            "Epoch 2/10, Batch 0/938, Loss: 0.014973055571317673\n",
            "Epoch 2/10, Batch 100/938, Loss: 0.003984479233622551\n",
            "Epoch 2/10, Batch 200/938, Loss: 0.07035911828279495\n",
            "Epoch 2/10, Batch 300/938, Loss: 0.04827844724059105\n",
            "Epoch 2/10, Batch 400/938, Loss: 0.0419294610619545\n",
            "Epoch 2/10, Batch 500/938, Loss: 0.03147599846124649\n",
            "Epoch 2/10, Batch 600/938, Loss: 0.0008587393094785511\n",
            "Epoch 2/10, Batch 700/938, Loss: 0.011603101156651974\n",
            "Epoch 2/10, Batch 800/938, Loss: 0.018550965934991837\n",
            "Epoch 2/10, Batch 900/938, Loss: 0.1043575257062912\n",
            "Epoch 3/10, Batch 0/938, Loss: 0.003684469498693943\n",
            "Epoch 3/10, Batch 100/938, Loss: 0.013857990503311157\n",
            "Epoch 3/10, Batch 200/938, Loss: 0.006651653442531824\n",
            "Epoch 3/10, Batch 300/938, Loss: 0.013397334143519402\n",
            "Epoch 3/10, Batch 400/938, Loss: 0.0780152752995491\n",
            "Epoch 3/10, Batch 500/938, Loss: 0.0004545380943454802\n",
            "Epoch 3/10, Batch 600/938, Loss: 0.02752114273607731\n",
            "Epoch 3/10, Batch 700/938, Loss: 0.01025701966136694\n",
            "Epoch 3/10, Batch 800/938, Loss: 0.010482107289135456\n",
            "Epoch 3/10, Batch 900/938, Loss: 0.019605131819844246\n",
            "Epoch 4/10, Batch 0/938, Loss: 0.008438191376626492\n",
            "Epoch 4/10, Batch 100/938, Loss: 0.00788103137165308\n",
            "Epoch 4/10, Batch 200/938, Loss: 0.000629457994364202\n",
            "Epoch 4/10, Batch 300/938, Loss: 0.0001672088837949559\n",
            "Epoch 4/10, Batch 400/938, Loss: 0.026125604286789894\n",
            "Epoch 4/10, Batch 500/938, Loss: 0.00014095760707277805\n",
            "Epoch 4/10, Batch 600/938, Loss: 0.0016777829732745886\n",
            "Epoch 4/10, Batch 700/938, Loss: 0.0016962707741186023\n",
            "Epoch 4/10, Batch 800/938, Loss: 0.01220042072236538\n",
            "Epoch 4/10, Batch 900/938, Loss: 0.001417785999365151\n",
            "Epoch 5/10, Batch 0/938, Loss: 0.0005295563023537397\n",
            "Epoch 5/10, Batch 100/938, Loss: 0.014334028586745262\n",
            "Epoch 5/10, Batch 200/938, Loss: 0.00016269135812763125\n",
            "Epoch 5/10, Batch 300/938, Loss: 0.0006735145580023527\n",
            "Epoch 5/10, Batch 400/938, Loss: 0.00020683699403889477\n",
            "Epoch 5/10, Batch 500/938, Loss: 0.0022849873639643192\n",
            "Epoch 5/10, Batch 600/938, Loss: 0.02195316180586815\n",
            "Epoch 5/10, Batch 700/938, Loss: 0.0011141648283228278\n",
            "Epoch 5/10, Batch 800/938, Loss: 0.00012932765821460634\n",
            "Epoch 5/10, Batch 900/938, Loss: 0.007961883209645748\n",
            "Epoch 6/10, Batch 0/938, Loss: 9.260366641683504e-05\n",
            "Epoch 6/10, Batch 100/938, Loss: 0.00533278938382864\n",
            "Epoch 6/10, Batch 200/938, Loss: 9.552355186315253e-05\n",
            "Epoch 6/10, Batch 300/938, Loss: 0.002092205686494708\n",
            "Epoch 6/10, Batch 400/938, Loss: 0.0014185538748279214\n",
            "Epoch 6/10, Batch 500/938, Loss: 0.06304840743541718\n",
            "Epoch 6/10, Batch 600/938, Loss: 4.5146931370254606e-05\n",
            "Epoch 6/10, Batch 700/938, Loss: 0.008976535871624947\n",
            "Epoch 6/10, Batch 800/938, Loss: 2.5875840947264805e-05\n",
            "Epoch 6/10, Batch 900/938, Loss: 0.002635363955050707\n",
            "Epoch 7/10, Batch 0/938, Loss: 0.0031422064639627934\n",
            "Epoch 7/10, Batch 100/938, Loss: 0.00045162218157202005\n",
            "Epoch 7/10, Batch 200/938, Loss: 0.0011967376340180635\n",
            "Epoch 7/10, Batch 300/938, Loss: 0.0004465971724130213\n",
            "Epoch 7/10, Batch 400/938, Loss: 0.0010247172322124243\n",
            "Epoch 7/10, Batch 500/938, Loss: 0.01917356066405773\n",
            "Epoch 7/10, Batch 600/938, Loss: 0.0009408515179529786\n",
            "Epoch 7/10, Batch 700/938, Loss: 3.217818448320031e-05\n",
            "Epoch 7/10, Batch 800/938, Loss: 0.0011214115656912327\n",
            "Epoch 7/10, Batch 900/938, Loss: 0.0010147736174985766\n",
            "Epoch 8/10, Batch 0/938, Loss: 0.00035960492095910013\n",
            "Epoch 8/10, Batch 100/938, Loss: 0.0002408718573860824\n",
            "Epoch 8/10, Batch 200/938, Loss: 0.027255456894636154\n",
            "Epoch 8/10, Batch 300/938, Loss: 1.0109135473612696e-05\n",
            "Epoch 8/10, Batch 400/938, Loss: 0.003590173786506057\n",
            "Epoch 8/10, Batch 500/938, Loss: 0.00014433042088057846\n",
            "Epoch 8/10, Batch 600/938, Loss: 0.0004432245623320341\n",
            "Epoch 8/10, Batch 700/938, Loss: 0.00011466870637377724\n",
            "Epoch 8/10, Batch 800/938, Loss: 0.004966347012668848\n",
            "Epoch 8/10, Batch 900/938, Loss: 3.916531932190992e-05\n",
            "Epoch 9/10, Batch 0/938, Loss: 0.00015125179197639227\n",
            "Epoch 9/10, Batch 100/938, Loss: 0.00026066333521157503\n",
            "Epoch 9/10, Batch 200/938, Loss: 0.003534966381266713\n",
            "Epoch 9/10, Batch 300/938, Loss: 2.170935294998344e-05\n",
            "Epoch 9/10, Batch 400/938, Loss: 0.0003895852423738688\n",
            "Epoch 9/10, Batch 500/938, Loss: 1.4964900401537307e-05\n",
            "Epoch 9/10, Batch 600/938, Loss: 0.0005264169885776937\n",
            "Epoch 9/10, Batch 700/938, Loss: 0.00014738792378921062\n",
            "Epoch 9/10, Batch 800/938, Loss: 2.1718808056903072e-05\n",
            "Epoch 9/10, Batch 900/938, Loss: 0.0046348352916538715\n",
            "Epoch 10/10, Batch 0/938, Loss: 0.00022862704645376652\n",
            "Epoch 10/10, Batch 100/938, Loss: 1.1934091162402183e-05\n",
            "Epoch 10/10, Batch 200/938, Loss: 0.0027365991845726967\n",
            "Epoch 10/10, Batch 300/938, Loss: 0.006688421126455069\n",
            "Epoch 10/10, Batch 400/938, Loss: 0.0007823469350114465\n",
            "Epoch 10/10, Batch 500/938, Loss: 0.0002829813747666776\n",
            "Epoch 10/10, Batch 600/938, Loss: 0.0004387390799820423\n",
            "Epoch 10/10, Batch 700/938, Loss: 0.0001198744575958699\n",
            "Epoch 10/10, Batch 800/938, Loss: 0.0043192217126488686\n",
            "Epoch 10/10, Batch 900/938, Loss: 3.089511665166356e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(pred, target):\n",
        "    correct = pred.eq(target.view_as(pred)).sum().item()\n",
        "    return correct"
      ],
      "metadata": {
        "id": "5jEb_Zo4CvNT"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = 0\n",
        "correct = 0\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for data , labels in test_loader:\n",
        "    data, target = data.to(device), labels.to(device)\n",
        "    output = model(data)\n",
        "    #print(output.shape, target.shape)\n",
        "    test_loss += criterion(output , target).item()\n",
        "    pred = output.argmax(dim=1 , keepdim = True)\n",
        "    correct += calculate_accuracy(pred , target)\n",
        "test_loss /= len(test_loader.dataset)\n",
        "accuracy = correct / len(test_loader.dataset)\n",
        "\n",
        "print(f\"accuracy : {accuracy}\")\n",
        "print(f\"loss : {test_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zLkD-1_Dr0N",
        "outputId": "387b5fce-2d7d-4955-9999-8ef02a629730"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy : 0.9908\n",
            "loss : 4.261492900550366e-05\n"
          ]
        }
      ]
    }
  ]
}